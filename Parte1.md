# üß© Gu√≠a de Estudio - Parte 1 del Examen (Preguntas y Respuestas)

---

## 1. ¬øCu√°les ser√≠an las variables dependientes, independientes e intervinientes en un experimento para evaluar una nueva web de compras con IA?

La variable independiente ser√≠a el redise√±o de la web o el uso del sistema inteligente (por ejemplo, recomendador personalizado). La variable dependiente podr√≠a ser el tiempo de permanencia en el sitio, el n√∫mero de clics o las conversiones. Las variables intervinientes pueden incluir el perfil del usuario (edad, experiencia tecnol√≥gica), la hora del d√≠a o el dispositivo utilizado. Dise√±ar el experimento requiere establecer dos grupos (A/B), controlar las variables externas y medir objetivamente los resultados.

---

## 2. ¬øQu√© roles incluir√≠as en el equipo de desarrollo de un chatbot con PLN y c√≥mo organizar√≠as el trabajo?

Incluir√≠a roles como cient√≠fico de datos (para entrenar el modelo de lenguaje), ingeniero de backend (para desplegar la API), dise√±ador UX (para flujos de conversaci√≥n), experto en dominio (para el contenido) y un gestor de proyecto. Se trabajar√≠a con metodolog√≠a √°gil, organizando tareas en sprints, con entregables iterativos como versiones del bot, pruebas de usuario y ajustes sem√°nticos. La comunicaci√≥n clara y la integraci√≥n continua ser√≠an claves para el √©xito.

---

## 3. Describe una estrategia para mantener actualizado y monitorizado un modelo de detecci√≥n de fraude en una entidad financiera.

Se implementar√≠a un pipeline de MLOps con: ingesta de nuevos datos, validaci√≥n de calidad, test autom√°tico del modelo, reentrenamiento bajo ciertas condiciones (como cambio en la distribuci√≥n), y despliegue continuo (CI/CD). La monitorizaci√≥n incluir√≠a m√©tricas de precisi√≥n y alerta ante ca√≠da de rendimiento o aumento de falsos negativos. Adem√°s, se usar√≠a un dashboard con logs, control de versiones de modelo y procesos de rollback ante errores.

---

## 4. ¬øC√≥mo afectan los datos sesgados a un sistema de reconocimiento facial y qu√© estrategias se pueden aplicar para corregirlo?

Los datos sesgados afectan la generalizaci√≥n del sistema. Si los datos de entrenamiento contienen mayoritariamente rostros de un grupo √©tnico o g√©nero, el sistema puede fallar en otros grupos. Para mitigarlo, se deben usar datasets balanceados, t√©cnicas de fairness-aware learning, auditor√≠as algor√≠tmicas y validaci√≥n cruzada con subgrupos. La transparencia sobre los datos usados tambi√©n es clave.

---

## 5. ¬øPor qu√© es importante garantizar la explicabilidad de un sistema de IA utilizado en el diagn√≥stico m√©dico?

La explicabilidad permite que los profesionales m√©dicos entiendan por qu√© el sistema sugiere un diagn√≥stico, lo que facilita su aceptaci√≥n y validaci√≥n. Adem√°s, es necesaria para detectar errores, justificar decisiones y evitar responsabilidad legal por decisiones incorrectas. Herramientas como SHAP o LIME ayudan a visualizar qu√© variables han sido determinantes. Un sistema opaco, aunque preciso, podr√≠a no ser confiable sin explicabilidad.

---

## 6. ¬øQu√© ventajas ofrece aplicar el m√©todo cient√≠fico en la planificaci√≥n de un proyecto de IA educativo?

Aplicar el m√©todo cient√≠fico permite dise√±ar hip√≥tesis comprobables (por ejemplo, ‚Äúlos estudiantes con tutor√≠a IA rinden un 20% m√°s‚Äù), organizar el experimento (grupos control y tratamiento), y analizar resultados con m√©tricas como notas o retenci√≥n. Esto proporciona rigurosidad, objetividad y la posibilidad de replicar el estudio. Adem√°s, ayuda a justificar decisiones ante revisores o financiadores.

---

## 7. ¬øQu√© medidas tomar√≠as para evitar la reidentificaci√≥n de usuarios en un sistema que procesa datos sensibles?

Usar√≠a t√©cnicas de anonimizaci√≥n como agregaci√≥n, eliminaci√≥n de atributos clave o hashing irreversible. Adem√°s, evitar√≠a datos de localizaci√≥n o tiempo precisos que puedan correlacionarse con la identidad. Aplicar√≠a el principio de privacidad por dise√±o, solo recolectando lo estrictamente necesario y controlando accesos. Tambi√©n documentar√≠a el riesgo residual asumido y las medidas de mitigaci√≥n implementadas.

---

## 8. ¬øQu√© tipo de aprendizaje usar√≠as para un sistema que analiza im√°genes satelitales agr√≠colas, y por qu√©?

Usar√≠a aprendizaje supervisado si dispongo de etiquetas (por ejemplo, tipo de cultivo o grado de madurez). T√©cnicas como redes convolucionales permiten segmentar o clasificar regiones. Si no hay etiquetas, optar√≠a por aprendizaje no supervisado (como clustering) para agrupar patrones similares. La elecci√≥n depende de la disponibilidad de datos y del objetivo: detecci√≥n de anomal√≠as, predicci√≥n de rendimiento o mapeo de zonas.

---

## 9. ¬øQu√© criterios aplicar√≠as para evaluar el rendimiento de un modelo de predicci√≥n de abandono escolar?

Aplicar√≠a m√©tricas como F1-score, recall y AUC-ROC, especialmente si las clases est√°n desbalanceadas. Tambi√©n usar√≠a validaci√≥n cruzada y analizar√≠a falsos negativos (estudiantes que se abandonan pero no fueron detectados). Evaluar√≠a la robustez del modelo en diferentes centros y cohortes, y si es posible, medir√≠a el impacto real en la toma de decisiones (por ejemplo, intervenci√≥n temprana).

---

## 10. ¬øC√≥mo aplicar√≠as el principio de explicabilidad en un modelo de IA que recomienda productos a usuarios?

Aunque el impacto puede ser menor que en medicina, la explicabilidad sigue siendo importante para ganar confianza y evitar sesgos ocultos. Se pueden mostrar explicaciones simples (‚Äúte recomendamos esto porque compraste X‚Äù) o usar t√©cnicas como LIME para entender los factores que m√°s pesaron. Tambi√©n es √∫til para mejorar el modelo y detectar errores en los datos o en las reglas de negocio.

---

## 11. ¬øQu√© desaf√≠os √©ticos presenta el uso de datos hist√≥ricos para entrenar modelos de selecci√≥n de personal?

Los datos hist√≥ricos pueden reflejar decisiones sesgadas (por ejemplo, contratar mayoritariamente hombres). Si no se corrige, el modelo reproducir√° esa discriminaci√≥n. Adem√°s, puede haber falta de consentimiento informado sobre el uso original de esos datos. Se requiere una revisi√≥n √©tica de las variables utilizadas, auditor√≠as peri√≥dicas, mecanismos de explicabilidad y transparencia ante los candidatos.

---

## 12. ¬øC√≥mo se gestiona un proyecto de IA aplicando principios de metodolog√≠a √°gil?

El trabajo se organiza en sprints (ciclos de 1-2 semanas), con entregables incrementales: recolecci√≥n de datos, primer modelo, evaluaci√≥n preliminar, etc. Se hacen reuniones breves diarias (dailies), revisiones y retrospectivas. Las tareas se priorizan en un backlog y el equipo es multidisciplinar. Esta metodolog√≠a permite adaptarse r√°pidamente a cambios en los datos, objetivos o resultados.

---

## 13. ¬øQu√© significa ‚Äúcode is the new law‚Äù en el contexto de algoritmos y responsabilidad?

Significa que el c√≥digo ‚Äîlas reglas programadas en un sistema algor√≠tmico‚Äî act√∫a como una forma de legislaci√≥n: define lo que est√° permitido o no. Esto es relevante cuando los algoritmos toman decisiones que afectan personas, como en justicia o finanzas. Por eso, su dise√±o debe incorporar principios √©ticos, ser auditable, explicable y respetar marcos legales. El poder normativo del c√≥digo exige transparencia y control.

---

## 14. ¬øC√≥mo se eval√∫a la fiabilidad de un sistema de IA que se usa en conducci√≥n aut√≥noma?

Se eval√∫a con m√©tricas como tasa de error, tiempo de reacci√≥n, robustez ante condiciones adversas (lluvia, oscuridad), y capacidad de generalizar. Se usan simulaciones masivas y pruebas en carretera. Adem√°s, se audita el comportamiento en situaciones √©ticamente complejas. La fiabilidad tambi√©n incluye aspectos de seguridad cibern√©tica y resistencia a ataques adversarios.

---

## 15. ¬øQu√© papel cumple la gobernanza de datos en proyectos de IA en administraci√≥n p√∫blica?

La gobernanza garantiza que los datos sean gestionados con calidad, seguridad y √©tica. Incluye definir qui√©n accede a qu√© datos, con qu√© prop√≥sito, c√≥mo se documentan y c√≥mo se audita su uso. Tambi√©n implica cumplimiento legal (ej. GDPR), protecci√≥n ante sesgos y trazabilidad. En administraci√≥n p√∫blica, es clave para mantener la confianza ciudadana y asegurar justicia en las decisiones algor√≠tmicas.

---

## 16. ¬øC√≥mo puede una IA contribuir a la toma de decisiones judiciales sin reemplazar a los jueces?

La IA puede actuar como asistente que clasifica jurisprudencia, encuentra similitudes entre casos o sugiere posibles resoluciones basadas en precedentes. Sin embargo, la decisi√≥n final debe recaer en un juez humano. Para no reemplazar el juicio humano, el sistema debe ser explicable, trazable y ajustado a principios legales. Tambi√©n debe auditarse su funcionamiento regularmente y prohibirse su uso en decisiones cr√≠ticas sin revisi√≥n.

---

## 17. ¬øPor qu√© es preferible usar modelos explicables en educaci√≥n frente a redes neuronales profundas?

En educaci√≥n, es importante entender por qu√© un alumno es clasificado como ‚Äúen riesgo‚Äù o por qu√© se recomienda cierto material. Los modelos explicables permiten que docentes o tutores comprendan y validen las decisiones, generando confianza y mejorando la intervenci√≥n pedag√≥gica. Las redes profundas pueden ser m√°s precisas, pero dif√≠ciles de justificar ante una familia o un comit√© acad√©mico.

---

## 18. ¬øC√≥mo contribuyen las ontolog√≠as al funcionamiento de un sistema cognitivo basado en IA?

Las ontolog√≠as estructuran el conocimiento: definen conceptos, relaciones y jerarqu√≠as. En un sistema cognitivo, permiten que la IA ‚Äúentienda‚Äù el dominio (por ejemplo, medicina, educaci√≥n) y razone con sentido. Tambi√©n facilitan la interoperabilidad con otros sistemas y mejoran la capacidad de responder preguntas complejas. Son especialmente √∫tiles en sistemas expertos y asistentes conversacionales.

---

## 19. ¬øQu√© ventajas ofrece el aprendizaje federado en proyectos que manejan datos sensibles?

El aprendizaje federado permite entrenar modelos sin centralizar los datos. Los datos se quedan en sus dispositivos o instituciones, y solo se comparten actualizaciones de los modelos. Esto mejora la privacidad, reduce riesgos de fuga y permite cumplir con normativas como GDPR. Es √∫til en salud, banca o educaci√≥n, donde los datos son confidenciales.

---

## 20. ¬øC√≥mo usar√≠as la estrategia de fairness-aware learning en un modelo de cr√©dito bancario?

Aplicar√≠a t√©cnicas que penalicen desigualdades en el desempe√±o del modelo seg√∫n grupos demogr√°ficos. Por ejemplo, ajustes en la funci√≥n de p√©rdida para equilibrar false positives entre hombres y mujeres. Tambi√©n podr√≠a utilizar t√©cnicas de preprocesamiento (remuestreo), inprocesamiento (algoritmos justos) o postprocesamiento (ajuste de scores). El objetivo es que el modelo sea igual de preciso sin discriminar por edad, g√©nero u origen.

---

## 21. ¬øC√≥mo influye la calidad del dataset en la validez de un proyecto de investigaci√≥n en IA?

La calidad del dataset es fundamental para garantizar que los resultados del modelo sean v√°lidos y √∫tiles. Datos incompletos, mal etiquetados o sesgados pueden llevar a conclusiones err√≥neas y comprometer la generalizaci√≥n del modelo. Es necesario evaluar el origen, limpieza, balance, y representatividad de los datos, ya que un modelo entrenado sobre datos deficientes producir√° decisiones poco confiables y con potenciales riesgos sociales o √©ticos.

---

## 22. ¬øCu√°l es la diferencia entre una hip√≥tesis descriptiva y una predictiva en un proyecto de IA?

Una hip√≥tesis descriptiva busca observar y describir una relaci√≥n entre variables, sin necesariamente anticipar un resultado. Por ejemplo, ‚Äúlos estudiantes con m√°s participaci√≥n obtienen mejores calificaciones‚Äù. En cambio, una hip√≥tesis predictiva plantea una relaci√≥n que ser√° validada emp√≠ricamente mediante modelos, como ‚Äúuna red neuronal puede predecir el abandono escolar con un 90% de precisi√≥n‚Äù. La predictiva es m√°s com√∫n en proyectos de IA por su enfoque experimental.

---

## 23. ¬øC√≥mo se aplica el principio de transparencia en el desarrollo de proyectos de IA?

La transparencia exige que las decisiones tomadas durante el dise√±o, desarrollo y despliegue de un sistema de IA sean documentadas y comprensibles. Implica explicar c√≥mo funciona el algoritmo, de d√≥nde provienen los datos, qu√© m√©tricas se usan y c√≥mo se eval√∫a el sistema. Tambi√©n incluye informar a los usuarios si est√°n interactuando con una IA, y permitir auditor√≠as externas. Es esencial para garantizar confianza y responsabilidad en entornos sensibles como justicia, salud o educaci√≥n.

---

## 24. ¬øQu√© problemas puede generar el sobreajuste en modelos de IA aplicados a educaci√≥n?

El sobreajuste ocurre cuando un modelo aprende demasiado bien los patrones del conjunto de entrenamiento, incluso el ruido, y pierde capacidad de generalizaci√≥n. En educaci√≥n, esto puede traducirse en sistemas que solo funcionan con una cohorte espec√≠fica de estudiantes, generando intervenciones err√≥neas en nuevos contextos. Adem√°s, puede reforzar patrones no generalizables y comprometer decisiones pedag√≥gicas. Es crucial aplicar regularizaci√≥n, validaci√≥n cruzada y revisi√≥n continua.

---

## 25. ¬øQu√© factores considerar√≠as para elegir entre aprendizaje supervisado y no supervisado en un proyecto?

La decisi√≥n depende de si se tienen etiquetas o no. Si contamos con datos clasificados (por ejemplo, √©xito o fracaso escolar), usamos aprendizaje supervisado. Si no hay etiquetas pero queremos encontrar estructuras ocultas, como perfiles de usuarios, se aplica el no supervisado. Otros factores incluyen la cantidad de datos disponibles, la complejidad de la tarea y los recursos t√©cnicos y humanos. A veces se combinan ambos enfoques.

---

## 26. ¬øQu√© caracter√≠sticas hacen que una investigaci√≥n en IA sea considerada replicable?

Una investigaci√≥n replicable debe documentar todo: datasets utilizados, c√≥digo fuente, configuraci√≥n de modelos, m√©tricas, entorno de ejecuci√≥n y semilla aleatoria. Tambi√©n se deben explicar claramente los pasos de preprocesamiento y criterios de evaluaci√≥n. Publicar el c√≥digo en repositorios abiertos y proporcionar instrucciones claras son pr√°cticas clave. La replicabilidad fortalece la credibilidad cient√≠fica y permite mejorar modelos existentes de forma colaborativa.

---

## 27. ¬øCu√°l es el impacto del sesgo de confirmaci√≥n en la interpretaci√≥n de resultados de IA?

El sesgo de confirmaci√≥n puede llevar a que investigadores o equipos interpreten los resultados de un modelo de manera parcial, privilegiando las m√©tricas que confirman sus expectativas y desestimando las que las contradicen. Esto puede resultar en modelos sobrevalorados, errores metodol√≥gicos no detectados, o decisiones basadas en supuestos equivocados. Para mitigarlo, es importante contrastar con l√≠neas base, realizar pruebas A/B y fomentar revisiones por pares.

---

## 28. ¬øQu√© beneficios aporta el uso de simulaciones en fases tempranas de un proyecto de IA?

Las simulaciones permiten experimentar con escenarios hipot√©ticos sin los costos o riesgos asociados al uso de datos reales. Son √∫tiles cuando los datos son escasos, confidenciales o costosos de obtener. Adem√°s, ayudan a validar hip√≥tesis, probar modelos preliminares, optimizar par√°metros y evaluar el rendimiento bajo diferentes condiciones. Son especialmente valiosas en educaci√≥n, salud y transporte, donde las pruebas en entornos reales pueden ser delicadas.

---

## 29. ¬øC√≥mo justificar√≠as la elecci√≥n de un tipo de red neuronal en un proyecto de clasificaci√≥n de texto?

La elecci√≥n depende del problema espec√≠fico. Si se trata de clasificar opiniones o sentimientos en textos cortos, un modelo tipo LSTM o GRU puede captar dependencias temporales. Si se busca analizar contexto profundo en textos largos, modelos basados en Transformers como BERT ofrecen mejor rendimiento. Tambi√©n se consideran los recursos disponibles, la interpretabilidad y la experiencia del equipo. Justificar esta elecci√≥n implica vincularla a la literatura y a las caracter√≠sticas del dataset.

---

## 30. ¬øQu√© funci√≥n cumple la revisi√≥n bibliogr√°fica en la definici√≥n del marco te√≥rico de un proyecto de IA?

La revisi√≥n bibliogr√°fica permite ubicar el problema en el estado del arte, evitar duplicaciones, identificar metodolog√≠as efectivas y vac√≠os de conocimiento. Tambi√©n orienta sobre qu√© m√©tricas usar, qu√© modelos son m√°s adecuados y qu√© problemas han sido previamente abordados. Una buena revisi√≥n aporta justificaci√≥n te√≥rica, enriquece la formulaci√≥n de hip√≥tesis y da credibilidad al planteamiento cient√≠fico.

---

## 31. ¬øEn qu√© consiste la trazabilidad en un proyecto de IA y por qu√© es relevante?

La trazabilidad es la capacidad de seguir el rastro de todos los elementos del proyecto: desde los datos crudos hasta los resultados finales. Permite auditar decisiones, corregir errores, explicar resultados y asegurar la integridad del sistema. Es clave para la reproducibilidad, el cumplimiento regulatorio y la confianza de usuarios y autoridades. Incluye versionado de datasets, seguimiento de experimentos y documentaci√≥n clara.

---

## 32. ¬øC√≥mo puede una IA generar conocimiento nuevo en un campo cient√≠fico?

La IA puede analizar grandes vol√∫menes de datos y detectar patrones que no son evidentes para los investigadores humanos. Esto permite generar hip√≥tesis novedosas, descubrir relaciones ocultas y proponer nuevas l√≠neas de investigaci√≥n. Por ejemplo, modelos en biolog√≠a han predicho interacciones entre prote√≠nas a√∫n no documentadas. La IA complementa la intuici√≥n cient√≠fica y expande la frontera del conocimiento cuando se usa con sentido cr√≠tico y validaci√≥n emp√≠rica.

---

## 33. ¬øPor qu√© es importante evitar variables redundantes o colineales al entrenar un modelo?

Las variables redundantes no aportan nueva informaci√≥n y pueden aumentar el tiempo de entrenamiento, mientras que la colinealidad puede generar inestabilidad en modelos lineales, dificultando la interpretaci√≥n y provocando varianzas elevadas en los coeficientes. Esto puede afectar negativamente el rendimiento del modelo y dar lugar a resultados enga√±osos. T√©cnicas como PCA, selecci√≥n de caracter√≠sticas y an√°lisis de correlaci√≥n ayudan a detectarlas y eliminarlas.

---

## 34. ¬øQu√© riesgos √©ticos implica la hiperpersonalizaci√≥n basada en IA?

La hiperpersonalizaci√≥n puede generar burbujas informativas, sesgos reforzados y manipulaci√≥n del comportamiento del usuario. Tambi√©n puede violar la privacidad si no se informa ni controla adecuadamente el uso de datos. En e-commerce, puede llevar a decisiones de compra basadas en presi√≥n algor√≠tmica. Por tanto, debe garantizarse el consentimiento informado, la transparencia sobre el perfilado, y ofrecer mecanismos de control al usuario.

---

## 35. ¬øQu√© diferencias existen entre validaci√≥n cruzada y validaci√≥n holdout?

La validaci√≥n holdout consiste en separar una porci√≥n fija de los datos para prueba, entrenando el modelo en el resto. Es r√°pida, pero sensible al azar del split. La validaci√≥n cruzada (k-fold) divide el dataset en m√∫ltiples particiones, entrena en k-1 y prueba en 1, repitiendo k veces. Ofrece una estimaci√≥n m√°s robusta del rendimiento y reduce la varianza de la evaluaci√≥n. Es preferible en proyectos donde se requiere rigor.

---

## 36. ¬øPor qu√© es importante dise√±ar el proyecto con reproducibilidad desde el inicio?

Dise√±ar con reproducibilidad garantiza que los resultados puedan ser verificados y extendidos por otros. Esto incluye fijar semillas aleatorias, usar entornos virtuales controlados, documentar decisiones, versionar datos y compartir el c√≥digo. La reproducibilidad no solo refuerza la credibilidad cient√≠fica, sino que permite auditar el proceso, detectar errores y facilitar el trabajo colaborativo.

---

## 37. ¬øC√≥mo afecta el uso de m√©tricas inadecuadas a la evaluaci√≥n de un modelo de IA?

El uso de m√©tricas incorrectas puede dar una falsa impresi√≥n del rendimiento del modelo. Por ejemplo, en problemas desbalanceados, la accuracy puede ser alta aunque el modelo falle en detectar la clase minoritaria. Elegir m√©tricas apropiadas (F1-score, precision-recall, AUC) seg√∫n el objetivo y el contexto es crucial para una evaluaci√≥n justa y √∫til. Tambi√©n se recomienda reportar varias m√©tricas complementarias.

---

## 38. ¬øQu√© aporta la combinaci√≥n de m√∫ltiples modelos (ensembles) a un proyecto de IA?

Los modelos de conjunto (ensembles) como Random Forest, XGBoost o modelos stacking combinan predicciones de varios modelos base para reducir el error y mejorar la estabilidad. Mitigan el riesgo de que un solo modelo est√© sesgado o sobreajustado. Aunque requieren m√°s recursos, ofrecen mejor generalizaci√≥n y suelen ganar en competencias pr√°cticas como Kaggle. Son √∫tiles en contextos cr√≠ticos que exigen precisi√≥n robusta.

---

## 39. ¬øC√≥mo se diferencia un sistema experto de una red neuronal en t√©rminos de conocimiento y explicabilidad?

Un sistema experto se basa en reglas expl√≠citas creadas por humanos expertos. Su ventaja es la trazabilidad y la explicabilidad total. En cambio, una red neuronal aprende patrones complejos de forma autom√°tica, pero su funcionamiento interno es dif√≠cil de interpretar. En aplicaciones donde se requiere justificar decisiones (por ejemplo, medicina o derecho), se suele preferir la transparencia de sistemas expertos o usar modelos h√≠bridos.

---

## 40. ¬øPor qu√© es importante distinguir entre correlaci√≥n y causalidad en an√°lisis con IA?

La IA puede identificar correlaciones, pero eso no implica causalidad. Si no se distingue entre ambas, se pueden tomar decisiones err√≥neas. Por ejemplo, que los usuarios que compran paraguas tambi√©n compren sopa no significa que uno cause el otro. Establecer causalidad requiere dise√±os experimentales, modelos estructurales o intervenciones controladas. Ignorar esta distinci√≥n puede llevar a sesgos, falsas atribuciones y modelos in√∫tiles.

---
