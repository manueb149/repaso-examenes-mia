# ğŸ—“ï¸ Clase del 21 de marzo de 2025

### ğŸ“š Tema: IntroducciÃ³n al aprendizaje automÃ¡tico

---

### ğŸ¯ **Objetivos de la clase:**

1. Presentar el enfoque y estructura general de la asignatura.
2. Introducir los conceptos fundamentales del aprendizaje automÃ¡tico.
3. Establecer la terminologÃ­a bÃ¡sica y la importancia del preprocesamiento de datos.
4. Explicar las expectativas de trabajo y el formato del examen.

---

### ğŸ§  **Contenidos tratados (resumen teÃ³rico + explicaciones del profesor):**

#### âœ… 1. Â¿QuÃ© es el aprendizaje automÃ¡tico (ML)?

* Se definiÃ³ como la disciplina que **permite a los sistemas aprender a partir de datos sin ser programados explÃ­citamente**.
* Se abordaron los **tres tipos principales**:

  * **Aprendizaje supervisado**: aprende a partir de datos etiquetados. Ej.: clasificaciÃ³n y regresiÃ³n.
  * **Aprendizaje no supervisado**: trabaja sin etiquetas. Ej.: clustering.
  * **Aprendizaje por refuerzo**: basado en recompensas por acciones. Usado en agentes autÃ³nomos.

ğŸ“Œ **Comentario del profesor:**

> â€œLo importante en supervisado es que se entrena un modelo a partir de ejemplos conocidos. La clave estÃ¡ en la relaciÃ³n entre las variables predictoras y la variable objetivo.â€

---

#### âœ… 2. Componentes de un problema de aprendizaje supervisado

* **Entrada (X)**: conjunto de caracterÃ­sticas o *features*.
* **Salida (y)**: variable objetivo (numÃ©rica o categÃ³rica).
* **Modelo**: funciÃ³n que intenta aprender la relaciÃ³n entre X e y.
* **Error o pÃ©rdida**: diferencia entre la predicciÃ³n del modelo y el valor real.

El objetivo de un modelo es **minimizar el error**.

---

#### âœ… 3. Tipos de problemas supervisados

* **ClasificaciÃ³n**: la salida es una etiqueta o clase. Ej.: Â¿es spam o no?
* **RegresiÃ³n**: la salida es un valor numÃ©rico continuo. Ej.: Â¿cuÃ¡nto costarÃ¡ una casa?

ğŸ“Œ **Ejemplo discutido:**

> Predecir si un cliente cancelarÃ¡ un servicio â†’ clasificaciÃ³n.
> Predecir el precio de un producto â†’ regresiÃ³n.

---

#### âœ… 4. Fases de un proyecto de ML (pipeline)

1. **RecolecciÃ³n y limpieza de datos**
2. **AnÃ¡lisis exploratorio (EDA)**
3. **TransformaciÃ³n y selecciÃ³n de caracterÃ­sticas**
4. **Entrenamiento del modelo**
5. **ValidaciÃ³n y evaluaciÃ³n**
6. **ImplementaciÃ³n y mantenimiento**

ğŸ“Œ **Comentario del profesor:**

> â€œEl preprocesamiento representa mÃ¡s del 70% del trabajo real. Un modelo bien entrenado con malos datos no servirÃ¡.â€

---

#### âœ… 5. RepresentaciÃ³n y tipos de variables

* **NumÃ©ricas (continuas o discretas)**: edad, ingresos, temperatura.
* **CategÃ³ricas**: color, estado civil.
* **Binarias**: sÃ­/no.
* **Ordinales**: bajo/medio/alto (tienen orden).

Es importante saber **cÃ³mo codificarlas** para que el modelo pueda utilizarlas.

---

#### âœ… 6. IntroducciÃ³n al tratamiento de datos

* **Valores nulos**: pueden eliminarse o imputarse.
* **Outliers**: identificarlos y tratarlos.
* **NormalizaciÃ³n y estandarizaciÃ³n**: para escalar valores y facilitar el entrenamiento.

ğŸ“Œ **Comentario del profesor:**

> â€œSi no escalas los datos, algunos modelos como SVM o regresiÃ³n logÃ­stica funcionarÃ¡n mal.â€

---

### ğŸ“ Sobre la asignatura y el examen:

* Se indicÃ³ que la asignatura se evaluarÃ¡ con:

  * Una parte teÃ³rica de conocimiento (pregunta aplicada).
  * Preguntas tipo test.
  * Un ejercicio prÃ¡ctico.
  * Un anÃ¡lisis con razonamiento justificado.

ğŸ“Œ **Comentario importante:**

> â€œEl examen **no requerirÃ¡ cÃ³digo Python**, sino justificar el uso de modelos, tÃ©cnicas o mÃ©tricas.â€

* TambiÃ©n se mencionÃ³ que a lo largo del curso se proporcionarÃ¡n:

  * PDFs de las sesiones.
  * Cuadernos de ejercicios.
  * Enlaces externos Ãºtiles.
  * CÃ³digos de ejemplo con datos sintÃ©ticos.

---

### ğŸ“Œ Ideas clave para repasar:

* Diferenciar bien entre **clasificaciÃ³n y regresiÃ³n**.
* Tener claro el **pipeline de Machine Learning** y sus fases.
* Saber identificar y transformar tipos de variables.
* Recordar que **los datos mandan**: preprocesamiento y calidad son esenciales.
* Estudiar las **etapas del aprendizaje supervisado** y cÃ³mo un modelo minimiza el error.

AquÃ­ tienes el **resumen detallado de la clase del 24 de marzo de 2025**, correspondiente a la segunda sesiÃ³n del curso de *TÃ©cnicas de Aprendizaje AutomÃ¡tico*. Esta clase continÃºa desarrollando el contenido del **Bloque 1**, con Ã©nfasis en el tratamiento de datos y la preparaciÃ³n de variables para el modelado.


# ğŸ—“ï¸ Clase del 24 de marzo de 2025

### ğŸ“š Tema: ContinuaciÃ³n del Bloque 1 â€” Tratamiento y transformaciÃ³n de datos

---

### ğŸ¯ **Objetivos de la clase:**

1. Profundizar en el preprocesamiento de datos y su importancia en el rendimiento de los modelos.
2. Entender el tratamiento adecuado de variables categÃ³ricas y numÃ©ricas.
3. Conocer las transformaciones necesarias antes del entrenamiento.
4. Introducir conceptos de selecciÃ³n y generaciÃ³n de caracterÃ­sticas.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + aportes del profesor):**

---

#### âœ… 1. RevisiÃ³n del concepto de aprendizaje automÃ¡tico supervisado

* Se repasan los conceptos de entrada (X), salida (y), modelo y error.
* Se recuerda la distinciÃ³n entre problemas de clasificaciÃ³n y regresiÃ³n.

ğŸ“Œ **Comentario del profesor:**

> â€œSiempre deben preguntarse: Â¿quÃ© tipo de variable tengo como salida? Eso les dirÃ¡ si estÃ¡n frente a una regresiÃ³n o clasificaciÃ³n.â€

---

#### âœ… 2. Tratamiento de variables categÃ³ricas

* No pueden ser utilizadas directamente por modelos que requieren entrada numÃ©rica.
* **TÃ©cnicas principales:**

  * **One-hot encoding:** crea una columna binaria por cada categorÃ­a (para variables nominales sin orden).
  * **Label encoding:** asigna un nÃºmero entero a cada categorÃ­a (adecuado solo si hay orden).
  * **Ordinal encoding:** Ãºtil cuando las categorÃ­as tienen jerarquÃ­a (ej.: bajo, medio, alto).

ğŸ“Œ **Advertencia del profesor:**

> â€œNo codifiquen con nÃºmeros enteros si no hay orden en la categorÃ­a. Eso confunde al modelo.â€

---

#### âœ… 3. Tratamiento de variables numÃ©ricas

* **Escalado:** importante para algoritmos sensibles a la magnitud (ej.: SVM, KNN, regresiÃ³n logÃ­stica).

  * **Min-Max Scaling:** transforma los valores al rango \[0,1].
  * **Z-score (standardization):** centra la media en 0 y la desviaciÃ³n estÃ¡ndar en 1.
* **Outliers:** deben identificarse y tratarse para evitar sesgos en el entrenamiento.

ğŸ“Œ **Comentario del profesor:**

> â€œSi usan SVM y no escalan, puede que el modelo falle estrepitosamente. No es opcional.â€

---

#### âœ… 4. DetecciÃ³n y tratamiento de valores nulos

* MÃ©todos:

  * EliminaciÃ³n de filas o columnas con muchos valores nulos.
  * ImputaciÃ³n: media, mediana, moda o incluso modelos de predicciÃ³n.

ğŸ“Œ **En clase se destacÃ³:**

> â€œLa imputaciÃ³n por mediana suele funcionar mejor si hay outliers. La media es sensible a ellos.â€

---

#### âœ… 5. GeneraciÃ³n y selecciÃ³n de caracterÃ­sticas

* **GeneraciÃ³n (Feature Engineering):** creaciÃ³n de nuevas variables a partir de las existentes (interacciones, combinaciones, transformaciones).
* **SelecciÃ³n:** elegir las variables mÃ¡s relevantes para el modelo.

  * Basada en estadÃ­sticas (correlaciÃ³n, ANOVA, chi-cuadrado).
  * MÃ©todos automÃ¡ticos (selecciÃ³n recursiva, regularizaciÃ³n).

ğŸ“Œ **Comentario del profesor:**

> â€œMÃ¡s variables no significa mejor modelo. Muchas veces empeoran el rendimiento si hay ruido.â€

---

#### âœ… 6. RepresentaciÃ³n de datos en el entorno de desarrollo

* Breve menciÃ³n a librerÃ­as como `pandas`, `scikit-learn` y `numpy`.
* Uso de DataFrames para manejo estructurado de datos.

---

### ğŸ“Œ Ideas clave para repasar:

* Dominar el uso correcto de one-hot vs label encoding.
* Comprender por quÃ© el escalado es fundamental para ciertos algoritmos.
* Saber cuÃ¡ndo imputar o eliminar datos faltantes.
* Reconocer el valor del *feature engineering* y la selecciÃ³n de variables.
* Identificar cÃ³mo los datos deben transformarse antes de alimentar un modelo.

---

### ğŸ“ Consejos del profesor:

* Practicar con datasets pequeÃ±os para observar cÃ³mo las transformaciones afectan al modelo.
* Entender que **el preprocesamiento es parte esencial del aprendizaje automÃ¡tico**, no un paso opcional.
* Usar datos sintÃ©ticos para controlar variaciones y aprender el impacto de las decisiones de transformaciÃ³n.

AquÃ­ tienes el **resumen detallado de la clase del 31 de marzo de 2025**, donde se inicia el **Bloque 2: EvaluaciÃ³n de modelos de aprendizaje supervisado**. Esta clase marca un punto de transiciÃ³n del preprocesamiento a la valoraciÃ³n formal de modelos, centrada en entender quÃ© tan bien funciona un modelo y por quÃ©.

# ğŸ—“ï¸ Clase del 31 de marzo de 2025

### ğŸ“š Tema: Inicio del Bloque 2 â€” EvaluaciÃ³n de modelos de aprendizaje automÃ¡tico supervisado

---

### ğŸ¯ **Objetivos de la clase:**

1. Comprender por quÃ© es necesario evaluar los modelos y no confiar Ãºnicamente en la mÃ©trica global.
2. Introducir las mÃ©tricas de evaluaciÃ³n para clasificaciÃ³n y regresiÃ³n.
3. Explicar conceptos clave como matriz de confusiÃ³n, sobreajuste y generalizaciÃ³n.
4. Familiarizarse con errores comunes al evaluar modelos.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + refuerzo del profesor):**

---

#### âœ… 1. Â¿Por quÃ© evaluar un modelo?

* El rendimiento en entrenamiento **no es garantÃ­a** de que el modelo generalice bien.
* La evaluaciÃ³n permite detectar **sobreajuste (overfitting)** o **subajuste (underfitting)**.
* Un buen modelo no es el que acierta todo en entrenamiento, sino el que se comporta bien con datos nuevos.

ğŸ“Œ **Comentario del profesor:**

> â€œSi tu modelo tiene 100% de acierto en entrenamiento, sospecha. Probablemente ha memorizado, no aprendido.â€

---

#### âœ… 2. Conjunto de datos: particiÃ³n

* Se divide el dataset en:

  * **Entrenamiento**
  * **ValidaciÃ³n** (opcional)
  * **Test** (evaluaciÃ³n final del modelo)
* IntroducciÃ³n al **cross-validation (validaciÃ³n cruzada)** como tÃ©cnica para evaluar con mayor robustez.

ğŸ“Œ **ExplicaciÃ³n clave:**

> â€œLa validaciÃ³n cruzada da una estimaciÃ³n mÃ¡s estable del rendimiento. Es lo que usamos para ajustar hiperparÃ¡metros.â€

---

#### âœ… 3. MÃ©tricas para clasificaciÃ³n

* **Accuracy (exactitud):** proporciÃ³n de aciertos.

  * âš ï¸ Puede ser engaÃ±osa si las clases estÃ¡n desbalanceadas.
* **Precision:** quÃ© proporciÃ³n de los positivos predichos eran verdaderos.
* **Recall (sensibilidad):** quÃ© proporciÃ³n de positivos reales fueron capturados.
* **F1-score:** media armÃ³nica entre precision y recall (equilibrio).
* **Matriz de confusiÃ³n:** tabla que compara las predicciones con los valores reales.

ğŸ“Œ **Comentario del profesor:**

> â€œNo usen accuracy en datasets desbalanceados. Les darÃ¡ una falsa sensaciÃ³n de Ã©xito.â€

---

#### âœ… 4. MÃ©tricas para regresiÃ³n

* **MAE (Mean Absolute Error):** error promedio sin penalizar en exceso grandes errores.
* **MSE (Mean Squared Error):** penaliza mÃ¡s los errores grandes.
* **RMSE (Root MSE):** raÃ­z cuadrada del MSE, en misma unidad que y.
* **RÂ² (Coeficiente de determinaciÃ³n):** quÃ© proporciÃ³n de la varianza de y es explicada por el modelo.

ğŸ“Œ **Consejo del profesor:**

> â€œRÂ² es muy intuitivo, pero puede ser engaÃ±oso si el modelo estÃ¡ mal especificado.â€

---

#### âœ… 5. Overfitting y underfitting

* **Overfitting:** modelo demasiado complejo que aprende incluso el ruido.
* **Underfitting:** modelo demasiado simple que no logra capturar el patrÃ³n.

ğŸ“Œ **Ejemplo prÃ¡ctico en clase:**

> ComparaciÃ³n visual de curvas: un modelo que se ajusta exactamente a cada punto vs uno que captura la tendencia.

---

#### âœ… 6. IntroducciÃ³n al concepto de curva ROC y AUC

* **ROC (Receiver Operating Characteristic):** representa la relaciÃ³n entre TPR (recall) y FPR.
* **AUC (Ãrea bajo la curva):** mide la capacidad del modelo para separar clases.

ğŸ“Œ **Nota del profesor:**

> â€œLa AUC se vuelve muy Ãºtil cuando tenemos que comparar clasificadores distintos. Cuanto mÃ¡s cerca de 1, mejor.â€

---

### ğŸ“Œ Ideas clave para repasar:

* No quedarse solo con accuracy: entender en quÃ© contexto es Ãºtil cada mÃ©trica.
* Saber interpretar una matriz de confusiÃ³n.
* Aprender a elegir mÃ©tricas segÃºn el problema: clasificaciÃ³n vs regresiÃ³n.
* Entender por quÃ© y cuÃ¡ndo usar validaciÃ³n cruzada.
* Tener claro el comportamiento del modelo frente a overfitting y underfitting.

---

### ğŸ“ Comentarios adicionales del profesor:

* Las mÃ©tricas serÃ¡n parte **fundamental de la secciÃ³n de anÃ¡lisis** en el examen.
* â€œTienen que saber justificar por quÃ© eligen una mÃ©trica y quÃ© les estÃ¡ diciendo sobre el modelo.â€
* Se anticipa que se presentarÃ¡n **resultados de modelos reales** en ejercicios prÃ¡cticos para ser interpretados.

AquÃ­ tienes el **resumen completo y detallado de la clase del 7 de abril de 2025**, continuaciÃ³n del Bloque 2, centrada en la profundizaciÃ³n de las **mÃ©tricas de evaluaciÃ³n**, su interpretaciÃ³n y la conexiÃ³n con el comportamiento del modelo en distintos contextos prÃ¡cticos.

# ğŸ—“ï¸ Clase del 7 de abril de 2025

### ğŸ“š Tema: ContinuaciÃ³n del Bloque 2 â€” EvaluaciÃ³n de modelos de clasificaciÃ³n y regresiÃ³n

---

### ğŸ¯ **Objetivos de la clase:**

1. Profundizar en el uso e interpretaciÃ³n de mÃ©tricas para clasificaciÃ³n y regresiÃ³n.
2. Identificar cuÃ¡ndo una mÃ©trica es mÃ¡s adecuada que otra.
3. Introducir la validaciÃ³n cruzada (cross-validation) como mÃ©todo de evaluaciÃ³n.
4. Relacionar las mÃ©tricas con decisiones prÃ¡cticas y el rendimiento del modelo.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + Ã©nfasis del profesor):**

---

#### âœ… 1. EvaluaciÃ³n de modelos de **clasificaciÃ³n**

* Se retoman las mÃ©tricas principales:

  * **Precision:** Ãºtil cuando el coste de un falso positivo es alto (ej.: detecciÃ³n de fraude).
  * **Recall:** Ãºtil cuando no se deben perder positivos (ej.: detecciÃ³n de cÃ¡ncer).
  * **F1-score:** equilibrio entre precision y recall.
* **Matriz de confusiÃ³n** como herramienta para calcular todas estas mÃ©tricas.

ğŸ“Œ **Comentario del profesor:**

> â€œLo importante no es solo saber calcular el F1, sino saber **cuÃ¡ndo usarlo y cÃ³mo interpretarlo**.â€

---

#### âœ… 2. EvaluaciÃ³n de modelos de **regresiÃ³n**

* RevisiÃ³n de mÃ©tricas:

  * **MAE:** robusto frente a outliers, fÃ¡cil de interpretar.
  * **MSE/RMSE:** penalizan errores grandes, Ãºtiles cuando se prioriza precisiÃ³n fina.
  * **RÂ²:** interpretabilidad intuitiva como proporciÃ³n de varianza explicada.
* Se enfatiza que estas mÃ©tricas **pueden dar resultados diferentes** y no hay una Ãºnica mejor en todos los casos.

ğŸ“Œ **ExplicaciÃ³n clave:**

> â€œNo es lo mismo predecir el precio de casas que la temperatura. **El error tolerable depende del contexto**.â€

---

#### âœ… 3. ValidaciÃ³n cruzada (Cross-Validation)

* TÃ©cnica de evaluaciÃ³n mÃ¡s robusta que usar un solo conjunto de test.
* **K-Fold Cross Validation:** el dataset se divide en K partes; se entrena con K-1 y se prueba con la restante.
* Se calcula la mÃ©trica en cada iteraciÃ³n y se hace la media.

ğŸ“Œ **Comentario del profesor:**

> â€œLa validaciÃ³n cruzada es **obligatoria** cuando haces tuning de hiperparÃ¡metros. Si no, estÃ¡s sobreajustando al test.â€

---

#### âœ… 4. SelecciÃ³n de mÃ©trica segÃºn el problema

* Para clasificaciÃ³n balanceada: accuracy puede ser razonable.
* Para clasificaciÃ³n desbalanceada: **mejor usar precision, recall, F1 o AUC.**
* Para regresiÃ³n: **usar varias mÃ©tricas** y comparar.

ğŸ“Œ **Ejemplo prÃ¡ctico del profesor:**

> â€œImagina que predices si una pieza estÃ¡ defectuosa y solo el 1% lo estÃ¡n. Un accuracy del 99% puede ser basura.â€

---

#### âœ… 5. Curvas ROC y AUC

* Se discute su uso cuando el modelo genera **probabilidades** en lugar de etiquetas.
* AUC mide la capacidad de un modelo para **distinguir entre clases**.
* ROC permite **comparar modelos** independientemente del umbral.

ğŸ“Œ **Nota del profesor:**

> â€œEs probable que en el examen les den una tabla de resultados o una curva. **Tienen que saber interpretarla.**â€

---

#### âœ… 6. MÃ©tricas y coste de error

* IntroducciÃ³n a **anÃ¡lisis de coste-beneficio** de errores:

  * Falsos positivos vs falsos negativos.
  * Dependencia del problema real (negocios, salud, etc.).
* Se enfatiza que no hay mÃ©trica mÃ¡gica, sino adecuada al **objetivo del sistema**.

ğŸ“Œ **ReflexiÃ³n en clase:**

> â€œUn modelo no es bueno o malo por su F1-score, sino por **cÃ³mo impacta su error en la vida real**.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Saber cuÃ¡ndo usar cada mÃ©trica.
* Entender las implicaciones de un alto recall vs alta precisiÃ³n.
* Ser capaz de leer una matriz de confusiÃ³n y extraer mÃ©tricas de ella.
* Aplicar validaciÃ³n cruzada para evitar overfitting.
* Relacionar la mÃ©trica con el objetivo del problema (negocio, salud, industria, etc.).

---

### ğŸ“ Consejos del profesor:

* â€œEn el examen, si les dan una tabla con valores de precision y recall, **no digan cuÃ¡l es mejor sin explicar por quÃ©**.â€
* Repasar ejemplos prÃ¡cticos donde el modelo predice mal y justificar quÃ© mÃ©trica serÃ­a mÃ¡s justa.
* Practicar interpretaciÃ³n de mÃ©tricas en casos de clasificaciÃ³n desbalanceada.


AquÃ­ tienes el **resumen completo y detallado de la clase del 22 de abril de 2025**, correspondiente al inicio del **Bloque 3: Modelos estadÃ­sticos y modelos no lineales**. Esta sesiÃ³n marca el paso de la evaluaciÃ³n de modelos al estudio de los algoritmos de aprendizaje supervisado en sÃ­, comenzando con los **modelos lineales y sus limitaciones**.

# ğŸ—“ï¸ Clase del 22 de abril de 2025

### ğŸ“š Tema: Inicio del Bloque 3 â€” Modelos estadÃ­sticos y modelos no lineales

---

### ğŸ¯ **Objetivos de la clase:**

1. Introducir los modelos lineales como punto de partida en aprendizaje supervisado.
2. Comprender sus supuestos, ventajas y limitaciones.
3. Explorar la diferencia entre modelos lineales y no lineales.
4. Analizar cuÃ¡ndo un modelo lineal es adecuado y cuÃ¡ndo no lo es.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + Ã©nfasis del profesor):**

---

#### âœ… 1. Modelos estadÃ­sticos y su lÃ³gica

* Se introducen como modelos con una base teÃ³rica **probabilÃ­stica o estadÃ­stica**, con **supuestos fuertes sobre los datos**.
* Ejemplo: **regresiÃ³n lineal** asume que la relaciÃ³n entre las variables es lineal, que los residuos son normales, homocedÃ¡sticos, e independientes.

ğŸ“Œ **Comentario del profesor:**

> â€œLa regresiÃ³n lineal funciona muy bienâ€¦ cuando se cumplen sus supuestos. Si no, es un desastre.â€

---

#### âœ… 2. RegresiÃ³n lineal simple y mÃºltiple

* **RegresiÃ³n lineal simple:** una variable independiente.

  * Modelo: y = Î²â‚€ + Î²â‚Â·x + Îµ

* **RegresiÃ³n lineal mÃºltiple:** varias variables independientes.

  * Modelo: y = Î²â‚€ + Î²â‚Â·xâ‚ + Î²â‚‚Â·xâ‚‚ + ... + Î²â‚™Â·xâ‚™ + Îµ

* Los coeficientes (Î²) se ajustan para minimizar el error cuadrÃ¡tico (mÃ­nimos cuadrados ordinarios).

* **InterpretaciÃ³n de los coeficientes:** cuÃ¡nto cambia y ante una unidad de cambio en x.

ğŸ“Œ **AclaraciÃ³n importante:**

> â€œUna de las grandes virtudes de la regresiÃ³n lineal es que es **fÃ¡cil de interpretar**.â€

---

#### âœ… 3. Limitaciones de los modelos lineales

* **No capturan relaciones no lineales** entre las variables.
* Son **muy sensibles a outliers**.
* Requieren que las variables no estÃ©n fuertemente correlacionadas entre sÃ­ (**colinealidad**).
* Generalmente **no funcionan bien con variables categÃ³ricas** sin una codificaciÃ³n adecuada.

ğŸ“Œ **Comentario del profesor:**

> â€œUn modelo lineal con muchas variables categÃ³ricas mal codificadas es como una receta con los ingredientes equivocados.â€

---

#### âœ… 4. IntroducciÃ³n a modelos no lineales

* Se define un modelo no lineal como aquel en el que la relaciÃ³n entre los parÃ¡metros y la salida **no es una combinaciÃ³n lineal**.
* **Ventaja:** pueden capturar relaciones complejas y patrones no evidentes.
* **Desventaja:** suelen ser menos interpretables y mÃ¡s propensos al sobreajuste.

ğŸ“Œ **TransiciÃ³n clave:**

> â€œAquÃ­ es donde aparecen los **Ã¡rboles de decisiÃ³n**, que veremos en la prÃ³xima clase.â€

---

#### âœ… 5. AplicaciÃ³n prÃ¡ctica de modelos lineales

* Casos donde **sÃ­ es recomendable** usar un modelo lineal:

  * RelaciÃ³n simple y clara entre variables.
  * Necesidad de interpretabilidad.
  * Datos bien comportados, sin ruido excesivo.

* Casos donde **NO se recomienda**:

  * RelaciÃ³n no lineal entre variables.
  * Gran cantidad de variables categÃ³ricas.
  * Datos con outliers o distribuciÃ³n no normal.

ğŸ“Œ **Ejemplo prÃ¡ctico:**

> Predecir precios de viviendas en un barrio homogÃ©neo â†’ regresiÃ³n lineal podrÃ­a funcionar.
> Predecir preferencias de usuario en un sistema de recomendaciÃ³n â†’ mejor un modelo no lineal.

---

### ğŸ“Œ Ideas clave para repasar:

* Saber **formular** un modelo de regresiÃ³n y estimar coeficientes.
* Entender **quÃ© significan los coeficientes** de un modelo lineal.
* Conocer **los supuestos** de la regresiÃ³n y cÃ³mo verificarlos.
* Identificar **cuÃ¡ndo conviene usar un modelo lineal y cuÃ¡ndo no.**
* Distinguir claramente entre modelos **lineales** y **no lineales**.

---

### ğŸ“ Consejos del profesor:

* â€œNo usen regresiÃ³n lineal por costumbre. PregÃºntense siempre si tiene sentido con los datos que tienen.â€
* â€œEn el examen podrÃ­an pedirles que justifiquen si un modelo lineal serÃ­a adecuado o no para un caso dado.â€
* Se recomienda practicar con datasets donde la relaciÃ³n entre variables sea tanto lineal como no lineal para observar diferencias.

AquÃ­ tienes el **resumen completo y detallado de la clase del 29 de abril de 2025**, continuaciÃ³n del Bloque 3, dedicada a los **Ã¡rboles de decisiÃ³n**, uno de los modelos no lineales mÃ¡s importantes y versÃ¡tiles del aprendizaje supervisado.

# ğŸ—“ï¸ Clase del 29 de abril de 2025

### ğŸ“š Tema: Bloque 3 (II) â€” Ãrboles de decisiÃ³n: estructura, funcionamiento y problemas

---

### ğŸ¯ **Objetivos de la clase:**

1. Comprender la estructura y lÃ³gica de los Ã¡rboles de decisiÃ³n.
2. Explicar cÃ³mo se construyen y cÃ³mo toman decisiones.
3. Identificar ventajas y desventajas del modelo.
4. Introducir el concepto de sobreajuste y su relaciÃ³n con los Ã¡rboles.
5. Explicar los criterios de divisiÃ³n y tÃ©cnicas de poda.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + explicaciones del profesor):**

---

#### âœ… 1. Â¿QuÃ© es un Ã¡rbol de decisiÃ³n?

* Modelo predictivo que **representa decisiones como una estructura jerÃ¡rquica de preguntas**.
* Se construye dividiendo el conjunto de datos en subconjuntos mÃ¡s homogÃ©neos.
* Cada **nodo interno** representa una condiciÃ³n sobre una variable.
* Cada **hoja** representa una predicciÃ³n final.

ğŸ“Œ **Ejemplo comentado en clase:**

> Si temperatura > 30 â†’ sÃ­ â†’ humedad > 70 â†’ sÃ­ â†’ â€œno jugar tenisâ€.

---

#### âœ… 2. ConstrucciÃ³n del Ã¡rbol (crecimiento)

* Se parte de la raÃ­z con todos los datos.
* En cada nodo se busca **la variable y el umbral que mejor separen los datos**.
* El proceso continÃºa **recursivamente** hasta cumplir un criterio de parada.

---

#### âœ… 3. Criterios de divisiÃ³n

* En clasificaciÃ³n:

  * **Ãndice Gini**
  * **EntropÃ­a (Information Gain)**
* En regresiÃ³n:

  * **Error cuadrÃ¡tico medio**
  * **ReducciÃ³n de varianza**

ğŸ“Œ **Comentario del profesor:**

> â€œEl Ã­ndice Gini y la entropÃ­a suelen dar resultados similares, pero es Ãºtil saber cÃ³mo se calculan ambos.â€

---

#### âœ… 4. Poda del Ã¡rbol

* **Ãrboles muy grandes tienden al sobreajuste**: aprenden ruido del entrenamiento.
* La **poda** reduce el tamaÃ±o del Ã¡rbol para mejorar generalizaciÃ³n.

  * **Pre-poda:** limitar profundidad, nÃºmero mÃ­nimo de muestras por nodo, etc.
  * **Post-poda:** construir Ã¡rbol completo y luego eliminar nodos con bajo aporte.

ğŸ“Œ **Comentario destacado:**

> â€œSi no podan el Ã¡rbol, se puede ajustar perfecto al entrenamientoâ€¦ y fallar completamente con datos nuevos.â€

---

#### âœ… 5. Ventajas de los Ã¡rboles de decisiÃ³n

* Intuitivos y fÃ¡ciles de interpretar.
* Manejan variables numÃ©ricas y categÃ³ricas sin requerir normalizaciÃ³n.
* No necesitan escalado.
* Capacidad de capturar relaciones no lineales y jerÃ¡rquicas.

---

#### âœ… 6. Desventajas y riesgos

* **Alta varianza:** pequeÃ±as variaciones en los datos pueden cambiar mucho el Ã¡rbol.
* **Sobreajuste (overfitting):** especialmente si no se controla su crecimiento.
* **No son los mejores en precisiÃ³n bruta**, aunque sÃ­ en interpretabilidad.

---

#### âœ… 7. Aplicaciones tÃ­picas

* ClasificaciÃ³n mÃ©dica (sÃ­/no enfermo), decisiones de riesgo, segmentaciÃ³n de clientes, etc.

ğŸ“Œ **Comentario del profesor:**

> â€œEl Ã¡rbol por sÃ­ solo no suele ser el mejor, pero es muy Ãºtil y forma la base de muchos modelos ensemble.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Saber cÃ³mo se construye un Ã¡rbol: criterios de divisiÃ³n, nodos, hojas.
* Entender bien los conceptos de entropÃ­a e Ã­ndice Gini.
* Conocer tÃ©cnicas de **poda** para evitar sobreajuste.
* Identificar cuÃ¡ndo usar Ã¡rboles de decisiÃ³n y quÃ© tipo de datos requieren.
* Reconocer que los Ã¡rboles **pueden sobreajustarse fÃ¡cilmente si no se limitan**.

---

### ğŸ“ Consejos del profesor:

* â€œSepan interpretar un Ã¡rbol: si les dan uno en el examen, deben poder explicar cÃ³mo clasifica una observaciÃ³n.â€
* â€œPractiquen con ejemplos para entender cÃ³mo varÃ­an las predicciones si cambian los datos de entrada.â€
* â€œRecuerden: Ã¡rboles no necesitan normalizar, pero sÃ­ controlar su profundidad.â€

AquÃ­ tienes el **resumen detallado de la clase del 5 de mayo de 2025**, en la que se inicia el **Bloque 4: MÃ©todos de Ensemble**. Esta sesiÃ³n introduce uno de los pilares de los modelos avanzados de clasificaciÃ³n y regresiÃ³n: la combinaciÃ³n de mÃºltiples modelos para mejorar el rendimiento predictivo.

# ğŸ—“ï¸ Clase del 5 de mayo de 2025

### ğŸ“š Tema: Bloque 4 â€” MÃ©todos de Ensemble (I): Bagging, Boosting, Stacking

---

### ğŸ¯ **Objetivos de la clase:**

1. Comprender quÃ© es un mÃ©todo de ensemble y por quÃ© se utiliza.
2. Diferenciar entre Bagging, Boosting y Stacking.
3. Identificar los beneficios de combinar modelos frente a usar uno solo.
4. Introducir el concepto de variaciÃ³n y sesgo en modelos.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + Ã©nfasis del profesor):**

---

#### âœ… 1. Â¿QuÃ© es un mÃ©todo de ensemble?

* TÃ©cnica que **combina mÃºltiples modelos** para mejorar la precisiÃ³n y estabilidad de las predicciones.
* Principio general: **â€œla uniÃ³n hace la fuerzaâ€**.
* Dos grandes objetivos:

  * **Reducir la varianza** (mejor estabilidad).
  * **Reducir el sesgo** (mejor ajuste a los datos).

ğŸ“Œ **Comentario del profesor:**

> â€œUn modelo dÃ©bil se puede volver potente si se combina bien con otros.â€

---

#### âœ… 2. Bagging (Bootstrap Aggregating)

* TÃ©cnica de reducciÃ³n de varianza.
* Se entrenan mÃºltiples modelos sobre distintos subconjuntos aleatorios (con reemplazo) del conjunto de entrenamiento (**bootstrap**).
* Cada modelo vota (clasificaciÃ³n) o promedia (regresiÃ³n).
* Ejemplo clÃ¡sico: **Random Forest** (conjunto de Ã¡rboles entrenados con bagging).

ğŸ“Œ **Ventajas:**

* Reduce el sobreajuste al suavizar las predicciones.
* FÃ¡cil de paralelizar.
* Robusto ante datos ruidosos.

ğŸ“Œ **Comentario del profesor:**

> â€œEl Bagging es ideal cuando tienes un modelo con **alta varianza**, como un Ã¡rbol sin poda.â€

---

#### âœ… 3. Boosting

* TÃ©cnica de reducciÃ³n de sesgo.
* Los modelos se entrenan **secuencialmente**: cada uno se enfoca en los errores del anterior.
* Se asignan **pesos mayores a los errores** cometidos para que el siguiente modelo intente corregirlos.
* Modelos representativos:

  * **AdaBoost**
  * **Gradient Boosting Machines (GBM)**

ğŸ“Œ **Ventajas:**

* Puede lograr **mayor precisiÃ³n** que Bagging.
* Enfoca el aprendizaje en los casos difÃ­ciles.

ğŸ“Œ **Riesgos:**

* Mayor propensiÃ³n al **sobreajuste** si no se controlan los hiperparÃ¡metros.
* Mayor coste computacional.

ğŸ“Œ **Comentario del profesor:**

> â€œEl Boosting es muy potente, pero si te pasas, se ajusta tanto que aprende el ruido.â€

---

#### âœ… 4. Stacking (Stacked Generalization)

* TÃ©cnica que combina **diferentes tipos de modelos** (heterogÃ©neos).
* Se entrena un **meta-modelo final** que decide quÃ© predicciÃ³n usar entre los modelos base.
* Cada modelo base predice, y esas predicciones se convierten en variables de entrada para el meta-modelo.

ğŸ“Œ **Ventajas:**

* Aprovecha lo mejor de varios algoritmos.
* Suele mejorar el rendimiento si los modelos base son diversos y bien configurados.

ğŸ“Œ **Comentario del profesor:**

> â€œEl stacking es como tener expertos en distintas Ã¡reas y un jefe que decide a cuÃ¡l hacerle caso.â€

---

#### âœ… 5. ComparaciÃ³n general entre mÃ©todos

| MÃ©todo   | Entrenamiento | Objetivo principal    | Riesgo de overfitting |
| -------- | ------------- | --------------------- | --------------------- |
| Bagging  | Paralelo      | Reducir varianza      | Bajo                  |
| Boosting | Secuencial    | Reducir sesgo         | Medio/Alto            |
| Stacking | Combinado     | Combinar modelos base | Medio                 |

ğŸ“Œ **Comentario del profesor:**

> â€œEn el examen, podrÃ­an preguntarles cuÃ¡l usar segÃºn el tipo de problema o comportamiento del modelo.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Entender las diferencias entre Bagging, Boosting y Stacking.
* Saber cuÃ¡l tÃ©cnica aplicar segÃºn si hay **alto sesgo o alta varianza**.
* Recordar que:

  * Bagging = modelos independientes en paralelo.
  * Boosting = secuencia de modelos dependientes.
  * Stacking = mezcla con meta-modelo.

---

### ğŸ“ Consejos del profesor:

* â€œPractiquen interpretar grÃ¡ficos de aprendizaje de boosting para ver si estÃ¡ sobreajustando.â€
* â€œNo digan en el examen que un mÃ©todo es mejor sin **justificar para quÃ© caso especÃ­fico**.â€
* â€œAprender a identificar si un modelo tiene mÃ¡s sesgo o mÃ¡s varianza puede ser lo que les haga ganar ese punto extra.â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 19 de mayo de 2025**, que continÃºa con el **Bloque 4**, profundizando de forma tÃ©cnica y aplicada en los dos mÃ©todos ensemble mÃ¡s utilizados en la prÃ¡ctica: **Bagging y Boosting**.

# ğŸ—“ï¸ Clase del 19 de mayo de 2025

### ğŸ“š Tema: Bloque 4 (II) â€” Bagging y Boosting en detalle

---

### ğŸ¯ **Objetivos de la clase:**

1. Analizar en profundidad cÃ³mo funcionan internamente los mÃ©todos de Bagging y Boosting.
2. Comprender sus ventajas y limitaciones prÃ¡cticas.
3. Estudiar algoritmos especÃ­ficos: Random Forest y AdaBoost.
4. Preparar criterios para saber cuÃ¡ndo usar cada mÃ©todo segÃºn el problema.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + Ã©nfasis del profesor):**

---

#### âœ… 1. Bagging: RevisiÃ³n tÃ©cnica

* Reafirma que **Bagging es ideal para modelos de alta varianza** (como Ã¡rboles de decisiÃ³n).
* Cada modelo se entrena con un **bootstrap sample** (subconjunto aleatorio con reemplazo).
* Los resultados se combinan por **votaciÃ³n (clasificaciÃ³n)** o **promedio (regresiÃ³n)**.

ğŸ“Œ **Comentario del profesor:**

> â€œCon Bagging no buscamos mejorar el sesgo, sino estabilizar modelos que fluctÃºan mucho con los datos.â€

---

#### âœ… 2. Random Forest

* Ejemplo clÃ¡sico de Bagging aplicado a Ã¡rboles de decisiÃ³n.
* AÃ±ade **aleatoriedad en la selecciÃ³n de atributos** al construir cada Ã¡rbol.
* Esto evita que todos los Ã¡rboles sean iguales y mejora la diversidad.
* Se utilizan **muchos Ã¡rboles pequeÃ±os y no podados**.

ğŸ“Œ **Ventajas clave:**

* Robustez al ruido y a datos faltantes.
* Buena precisiÃ³n sin sobreajuste.
* No requiere escalar datos ni transformar variables.

ğŸ“Œ **Comentario del profesor:**

> â€œEl Random Forest es uno de los modelos mÃ¡s utilizados en la industria por su fiabilidad general.â€

---

#### âœ… 3. Boosting: RevisiÃ³n tÃ©cnica

* Modelo secuencial: cada nuevo modelo intenta **corregir los errores del anterior**.
* Los errores se **ponderan mÃ¡s fuertemente** en el siguiente paso.
* Usa modelos dÃ©biles (por ejemplo, Ã¡rboles pequeÃ±os o â€˜stumpsâ€™).

ğŸ“Œ **Estrategia general:**

1. Entrenar primer modelo.
2. Evaluar errores.
3. Ajustar pesos.
4. Entrenar nuevo modelo.
5. Repetir.

---

#### âœ… 4. AdaBoost (Adaptive Boosting)

* Asigna pesos a las observaciones.
* Al inicio, todos los datos tienen el mismo peso.
* DespuÃ©s de cada iteraciÃ³n, **los errores se penalizan mÃ¡s**.
* La predicciÃ³n final es un **voto ponderado** de todos los modelos.

ğŸ“Œ **Ventajas:**

* Fuerte rendimiento con pocos modelos.
* Enfoca el aprendizaje en los casos difÃ­ciles.

ğŸ“Œ **Limitaciones:**

* Sensible a outliers y ruido.
* Si no se regula, tiende a sobreajustar.

ğŸ“Œ **Comentario del profesor:**

> â€œAdaBoost es como un alumno que presta mÃ¡s atenciÃ³n a los errores del examen anterior.â€

---

#### âœ… 5. Diferencias prÃ¡cticas clave entre Bagging y Boosting

| CaracterÃ­stica    | Bagging          | Boosting                     |
| ----------------- | ---------------- | ---------------------------- |
| Entrenamiento     | En paralelo      | Secuencial                   |
| Objetivo          | Reducir varianza | Reducir sesgo                |
| Modelo base       | Independiente    | Depende del anterior         |
| Sobrecarga        | Baja             | Alta (riesgo de overfitting) |
| Robustez al ruido | Alta             | Baja                         |

ğŸ“Œ **Comentario del profesor:**

> â€œSi tienen poco tiempo y datos ruidosos, usen Bagging. Si quieren afinar mucho con datos limpios, prueben Boosting.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Comprender el mecanismo de **muestreo con reemplazo** en Bagging.
* Entender cÃ³mo **se ajustan los pesos en AdaBoost**.
* Saber cuÃ¡ndo usar Random Forest (robustez) vs AdaBoost (precisiÃ³n).
* Recordar que Bagging mejora estabilidad y Boosting mejora ajuste.
* Identificar cuÃ¡ndo cada tÃ©cnica podrÃ­a fallar: Boosting con outliers, Bagging con modelos de alto sesgo.

---

### ğŸ“ Consejos del profesor:

* â€œEn el examen les pueden plantear un caso con un dataset ruidoso o muy lineal. Sepan justificar quÃ© tÃ©cnica ensemble usarÃ­an.â€
* â€œTienen que demostrar que entienden el impacto de la secuencia en Boosting: **no es lo mismo entrenar todo a la vez que aprender del error anterior.**â€
* â€œPractiquen interpretar salidas de Random Forest: importancia de variables, predicciÃ³n promedio, etc.â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 30 de mayo de 2025**, que cierra el recorrido temÃ¡tico del curso y estÃ¡ enfocada en ofrecer una visiÃ³n global del aprendizaje automÃ¡tico visto hasta el momento, con un **Ã©nfasis claro en el formato del examen**, cÃ³mo prepararse y quÃ© esperar.

---

# ğŸ—“ï¸ Clase del 30 de mayo de 2025

### ğŸ“š Tema: Cierre del curso â€” Repaso general y estructura del examen

---

### ğŸ¯ **Objetivos de la clase:**

1. Hacer un resumen de los bloques temÃ¡ticos del curso.
2. Explicar detalladamente la estructura del examen.
3. Ofrecer consejos prÃ¡cticos para enfrentarlo con Ã©xito.
4. Aclarar dudas frecuentes sobre lo que se evaluarÃ¡ (y lo que no).

---

### ğŸ§  **Contenidos tratados (resumen global + instrucciones clave del profesor):**

---

#### âœ… 1. RevisiÃ³n global de bloques del curso

* **Bloque 1: IntroducciÃ³n y tratamiento de datos**

  * Tipos de problemas: clasificaciÃ³n vs regresiÃ³n.
  * Tipos de variables, limpieza, escalado, codificaciÃ³n.
  * Importancia del preprocesamiento.

* **Bloque 2: EvaluaciÃ³n de modelos**

  * MÃ©tricas de clasificaciÃ³n y regresiÃ³n.
  * ValidaciÃ³n cruzada.
  * ElecciÃ³n adecuada de mÃ©trica segÃºn el problema.

* **Bloque 3: Modelos estadÃ­sticos y no lineales**

  * RegresiÃ³n lineal: ventajas y limitaciones.
  * Ãrboles de decisiÃ³n: estructura, crecimiento, poda.

* **Bloque 4: Ensemble**

  * Bagging, Boosting, Stacking: diferencias conceptuales, ventajas y riesgos.
  * Random Forest, AdaBoost: mecanismos y aplicaciones.

* **Bloque 5: OptimizaciÃ³n de hiperparÃ¡metros**

  * ParÃ¡metros vs hiperparÃ¡metros.
  * Grid Search vs Random Search.
  * Coste computacional, criterio de parada.

ğŸ“Œ **Comentario del profesor:**

> â€œTodo esto lo tienen que tener en mente, pero con especial foco en los conceptos, no en memorizar fÃ³rmulas.â€

---

#### âœ… 2. Estructura del examen

ğŸ§¾ El examen constarÃ¡ de **4 partes**, con un total de **10 puntos**:

1. **Conocimiento (1 punto)**

   * Pregunta teÃ³rica de desarrollo breve.
   * Se valorarÃ¡ la **comprensiÃ³n** de conceptos clave, no la extensiÃ³n.
   * Ejemplo: Â¿CuÃ¡ndo usarÃ­as F1-score en lugar de accuracy?

2. **Test (3 puntos)**

   * Seis preguntas tipo test (respuesta Ãºnica).
   * PuntuaciÃ³n:

     * +0.5 respuesta correcta
     * â€“0.25 respuesta incorrecta
     * 0 sin contestar
   * Basadas en definiciones, conceptos y diferenciaciÃ³n de tÃ©cnicas.

3. **Ejercicio prÃ¡ctico (3 puntos)**

   * Ejercicio similar a los del cuaderno o actividades prÃ¡cticas.
   * Puede implicar cÃ¡lculos sencillos o interpretaciÃ³n de resultados.

4. **AnÃ¡lisis con razonamiento (3 puntos)**

   * Caso prÃ¡ctico con preguntas asociadas.
   * Hay que **justificar respuestas, comparar modelos, evaluar mÃ©tricas**.

ğŸ“Œ **Aclaraciones importantes:**

* âŒ **No se pedirÃ¡ cÃ³digo.**
* âœ… Se podrÃ¡ usar bolÃ­grafo, calculadora simple, y plantilla de respuestas para el test.
* ğŸ§  Se valorarÃ¡ el razonamiento, la claridad, y el uso correcto de los tÃ©rminos tÃ©cnicos.

---

#### âœ… 3. Consejos para preparar el examen

* **Domina los conceptos clave**, especialmente:

  * Â¿QuÃ© modelo usarÃ­as y por quÃ©?
  * Â¿QuÃ© mÃ©trica es adecuada en cada contexto?
  * Â¿CuÃ¡ndo un modelo tiene sobreajuste?
  * Â¿QuÃ© tÃ©cnica ensemble aplicarÃ­as y por quÃ©?

* **Revisa los ejercicios de clase**:

  * Preguntas sobre tipos de variables.
  * InterpretaciÃ³n de mÃ©tricas.
  * DiferenciaciÃ³n de problemas (regresiÃ³n vs clasificaciÃ³n).
  * JustificaciÃ³n de transformaciones.

* **En la parte de anÃ¡lisis**:

  * Lee con calma el enunciado.
  * Subraya lo relevante.
  * Justifica cada respuesta con lÃ³gica, aunque no sepas el cÃ¡lculo exacto.

ğŸ“Œ **Comentario clave del profesor:**

> â€œUna respuesta incompleta pero bien razonada puede valer mÃ¡s que una completa sin sentido.â€

---

### ğŸ“Œ Ideas clave para repasar:

* EnfÃ³cate en **saber explicar conceptos**: no memorices, comprende.
* Aprende a **distinguir entre modelos y cuÃ¡ndo usarlos.**
* SÃ© capaz de **relacionar los conceptos del curso con un caso prÃ¡ctico**.
* No olvides que el examen valora **criterio, no cÃ³digo**.

---

### ğŸ“ Ãšltimas recomendaciones del profesor:

* â€œLean bien las preguntas. A veces lo que cambia es una palabra, y eso cambia la respuesta correcta.â€
* â€œPractiquen con los tests corregidos, pero no los memoricen sin entender.â€
* â€œTengan en cuenta que lo mÃ¡s importante es **argumentar con propiedad**.â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 2 de junio de 2025**, dedicada a la **revisiÃ³n de actividades anteriores, dudas frecuentes y preparaciÃ³n orientada al examen**. Esta clase funciona como una sesiÃ³n de entrenamiento prÃ¡ctico, enfocada en refinar criterios de evaluaciÃ³n, anÃ¡lisis de ejercicios y estructura de respuesta.

# ğŸ—“ï¸ Clase del 2 de junio de 2025

### ğŸ“š Tema: RevisiÃ³n de actividades â€” PreparaciÃ³n y simulaciÃ³n para el examen

---

### ğŸ¯ **Objetivos de la clase:**

1. Revisar actividades prÃ¡cticas realizadas durante el curso.
2. Identificar errores comunes en las respuestas de los estudiantes.
3. Entrenar la interpretaciÃ³n de resultados y justificaciÃ³n de decisiones.
4. Simular preguntas de anÃ¡lisis similares a las del examen.

---

### ğŸ§  **Contenidos tratados (repaso + enfoque estratÃ©gico):**

---

#### âœ… 1. RevisiÃ³n de actividades anteriores

* Se repasaron ejercicios donde el alumnado debÃ­a:

  * Identificar el tipo de problema (clasificaciÃ³n o regresiÃ³n).
  * Escoger un modelo apropiado.
  * Aplicar mÃ©tricas de evaluaciÃ³n correctamente.
  * Transformar variables antes de modelar.

ğŸ“Œ **Comentario del profesor:**

> â€œLa mayorÃ­a de errores vienen de **no justificar bien la elecciÃ³n de mÃ©trica o modelo**, no de hacer mal los cÃ¡lculos.â€

---

#### âœ… 2. Casos comunes discutidos en clase

**Caso 1:**

> *Predecir la cancelaciÃ³n de un contrato de cliente (sÃ­/no), con variables como edad, consumo y localizaciÃ³n.*

* Se esperaba identificarlo como **clasificaciÃ³n**.
* JustificaciÃ³n del uso de modelos como Ã¡rboles de decisiÃ³n, regresiÃ³n logÃ­stica, etc.
* Evaluar con **F1-score** o **AUC** por posible desbalance de clases.

**Caso 2:**

> *Predecir el importe mensual que un cliente gastarÃ¡ en el servicio.*

* Identificado como **regresiÃ³n**.
* AplicaciÃ³n de **regresiÃ³n lineal**, Random Forest Regressor, etc.
* EvaluaciÃ³n con **MAE o RMSE**.

ğŸ“Œ **Refuerzo del profesor:**

> â€œCada elecciÃ³n debe ir acompaÃ±ada de un **por quÃ©**. No vale decir â€˜uso Random Forestâ€™ sin justificaciÃ³n.â€

---

#### âœ… 3. PrÃ¡ctica con preguntas estilo examen

Se presentaron preguntas similares a las de la parte 4 del examen (anÃ¡lisis):

**Ejemplo:**

> â€œSe entrena un modelo SVM para clasificar clientes y se obtiene un accuracy de 95%, pero el recall es de 50%. Â¿CÃ³mo lo interpretarÃ­as?â€

**DiscusiÃ³n esperada:**

* Alta precisiÃ³n global, pero **mala capacidad para detectar positivos reales**.
* Indica un problema de **desequilibrio de clases o umbral de decisiÃ³n inadecuado**.
* Posibles soluciones: cambiar mÃ©trica de evaluaciÃ³n, rebalancear clases, ajustar hiperparÃ¡metros.

ğŸ“Œ **Comentario clave:**

> â€œSi tienen este tipo de pregunta en el examen, **analicen, comparen, propongan cambios y justifÃ­quenlos**.â€

---

#### âœ… 4. EvaluaciÃ³n de transformaciones

**Errores frecuentes:**

* Aplicar label encoding a variables sin orden.
* No escalar datos antes de SVM.
* Usar accuracy como Ãºnica mÃ©trica.

ğŸ“Œ **Refuerzo del profesor:**

> â€œTransformar mal los datos puede invalidar el modelo. Eso sÃ­ que se penaliza.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Practicar interpretaciÃ³n de mÃ©tricas con matrices de confusiÃ³n y resultados ambiguos.
* Justificar **por quÃ© se elige una mÃ©trica**, **cuÃ¡ndo se usa una tÃ©cnica de ensemble**, y **quÃ© transformaciÃ³n aplicar segÃºn el tipo de variable**.
* Leer cuidadosamente los enunciados de preguntas tipo anÃ¡lisis: subrayar variables, identificar salidas y estructuras de los datos.

---

### ğŸ“ Consejos finales del profesor:

* â€œEn el examen, si no saben calcular, al menos **expliquen bien lo que representa una mÃ©trica o decisiÃ³n**.â€
* â€œNo necesitan memorizar todos los mÃ©todos, pero sÃ­ entender **para quÃ© sirve cada uno**.â€
* â€œPractiquen pensar como si fueran ustedes quienes diseÃ±an el sistema de predicciÃ³n.â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 10 de junio de 2025**, correspondiente al inicio del **Bloque 5: OptimizaciÃ³n de modelos de aprendizaje supervisado**. Esta sesiÃ³n introduce la diferencia entre parÃ¡metros e hiperparÃ¡metros y los mÃ©todos sistemÃ¡ticos para encontrar la mejor configuraciÃ³n de un modelo.

# ğŸ—“ï¸ Clase del 10 de junio de 2025

### ğŸ“š Tema: Bloque 5 â€” OptimizaciÃ³n de modelos: hiperparÃ¡metros, bÃºsqueda y validaciÃ³n

---

### ğŸ¯ **Objetivos de la clase:**

1. Distinguir entre parÃ¡metros internos del modelo e hiperparÃ¡metros definidos por el usuario.
2. Conocer tÃ©cnicas de bÃºsqueda de hiperparÃ¡metros: Grid Search y Random Search.
3. Comprender el uso de validaciÃ³n cruzada para evaluar configuraciones.
4. Analizar el coste computacional y el criterio de parada de estas bÃºsquedas.

---

### ğŸ§  **Contenidos tratados (teorÃ­a + Ã©nfasis prÃ¡ctico del profesor):**

---

#### âœ… 1. ParÃ¡metros vs. HiperparÃ¡metros

* **ParÃ¡metros**: valores aprendidos automÃ¡ticamente durante el entrenamiento.
  Ejemplo: coeficientes Î² en regresiÃ³n lineal, pesos en una red neuronal.

* **HiperparÃ¡metros**: valores definidos **antes del entrenamiento**.
  Ejemplo: profundidad mÃ¡xima de un Ã¡rbol, nÃºmero de estimadores en Random Forest, C y Î³ en SVM.

ğŸ“Œ **Comentario del profesor:**

> â€œElegir bien los hiperparÃ¡metros es tan importante como elegir el modelo. Afectan directamente al rendimiento.â€

---

#### âœ… 2. BÃºsqueda en rejilla (Grid Search)

* Estrategia exhaustiva: explora todas las combinaciones posibles de hiperparÃ¡metros en una rejilla predefinida.
* Requiere definir los valores a probar para cada hiperparÃ¡metro.
* Se evalÃºa cada combinaciÃ³n mediante validaciÃ³n cruzada.

ğŸ“Œ **Ventajas:**

* FÃ¡cil de implementar.
* Garantiza que se prueban todas las opciones.

ğŸ“Œ **Desventajas:**

* Coste computacional elevado.
* Poca eficiencia cuando hay muchas combinaciones o hiperparÃ¡metros continuos.

---

#### âœ… 3. BÃºsqueda aleatoria (Random Search)

* En lugar de evaluar todas las combinaciones, selecciona aleatoriamente un nÃºmero fijo de combinaciones dentro del espacio definido.
* Ideal cuando se tienen **muchos hiperparÃ¡metros o rangos amplios**.

ğŸ“Œ **Ventajas:**

* Cobertura mÃ¡s diversa del espacio con menor coste.
* Probabilidad alta de encontrar una buena configuraciÃ³n en menos tiempo.

ğŸ“Œ **Comentario del profesor:**

> â€œEn la prÃ¡ctica, Random Search es mÃ¡s eficiente que Grid Search si no tienes idea de por dÃ³nde empezar.â€

---

#### âœ… 4. ValidaciÃ³n cruzada para evaluar combinaciones

* Se utiliza para estimar el rendimiento de cada combinaciÃ³n de hiperparÃ¡metros.
* Divide el conjunto de entrenamiento en K partes: entrena en Kâ€“1 y valida en la restante.
* Se calcula el rendimiento promedio de cada configuraciÃ³n.

ğŸ“Œ **Refuerzo del profesor:**

> â€œNunca usen el conjunto de test para elegir hiperparÃ¡metros. Para eso estÃ¡ la validaciÃ³n cruzada.â€

---

#### âœ… 5. Coste computacional y criterios de parada

* Cuanto mayor sea el nÃºmero de combinaciones, mayor serÃ¡ el coste.
* Criterios de parada:

  * NÃºmero mÃ¡ximo de iteraciones.
  * Tiempo mÃ¡ximo de bÃºsqueda.
  * Ausencia de mejora en cierto nÃºmero de pasos.

ğŸ“Œ **Advertencia del profesor:**

> â€œBuscar el mejor modelo estÃ¡ bien, pero no a cualquier precio. Hay que **compensar coste y ganancia**.â€

---

#### âœ… 6. Casos comunes en modelos reales

* Ejemplo: **Random Forest**

  * n\_estimators (nÃºmero de Ã¡rboles)
  * max\_depth (profundidad mÃ¡xima)
  * max\_features (nÃºmero de atributos a considerar en cada divisiÃ³n)

* Ejemplo: **SVM**

  * C (complejidad)
  * gamma (influencia del ejemplo en el kernel)

ğŸ“Œ **Comentario prÃ¡ctico:**

> â€œCon pocos datos, tal vez no haga falta optimizar nada. Pero con problemas reales, el ajuste fino puede marcar la diferencia.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Tener clara la diferencia entre parÃ¡metros y **hiperparÃ¡metros**.
* Saber cÃ³mo funciona **Grid Search** y **Random Search**, con ventajas y limitaciones.
* Comprender la importancia de la **validaciÃ³n cruzada** para no sobreajustar.
* Conocer ejemplos reales de hiperparÃ¡metros relevantes para modelos comunes.
* Entender el **balance entre precisiÃ³n del modelo y coste computacional**.

---

### ğŸ“ Consejos del profesor:

* â€œEn el examen les pueden pedir que propongan un proceso de optimizaciÃ³n para un modelo.â€
* â€œTienen que justificar quÃ© buscarÃ­an, cÃ³mo y por quÃ©. No basta con decir â€˜harÃ­a Grid Searchâ€™.â€
* â€œPractiquen con configuraciones de Random Forest y vean cÃ³mo cambia el rendimiento segÃºn el nÃºmero de Ã¡rboles.â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 16 de junio de 2025**, centrada en **casos prÃ¡cticos aplicados**, con especial Ã©nfasis en cÃ³mo se estructuran las preguntas de examen en su parte de anÃ¡lisis, ejercicio y test. Esta clase tiene un valor estratÃ©gico porque **anticipa tipos de ejercicios y errores comunes** que los estudiantes deben evitar.

# ğŸ—“ï¸ Clase del 16 de junio de 2025

### ğŸ“š Tema: AplicaciÃ³n prÃ¡ctica â€” Casos de examen, anÃ¡lisis, errores frecuentes y consejos

---

### ğŸ¯ **Objetivos de la clase:**

1. Entrenar la resoluciÃ³n de casos similares a los del examen.
2. Mostrar cÃ³mo razonar respuestas justificadas para preguntas abiertas.
3. Repasar temas propensos a aparecer en el test.
4. Identificar errores frecuentes en la interpretaciÃ³n de resultados.

---

### ğŸ§  **Contenidos tratados (casos reales + pautas del examen):**

---

#### âœ… 1. SimulaciÃ³n de preguntas del examen

Se revisaron **preguntas estructuradas como las del examen** (especialmente anÃ¡lisis y conocimiento). Ejemplos:

---

**â“Pregunta 1 (conocimiento)**

> â€œÂ¿CÃ³mo determinarÃ­as si un problema es de clasificaciÃ³n o de regresiÃ³n?â€

**Respuesta esperada:**

* Observar el tipo de variable objetivo:

  * NumÃ©rica continua â†’ regresiÃ³n.
  * CategÃ³rica o binaria â†’ clasificaciÃ³n.
* Ejemplo prÃ¡ctico para justificar.

ğŸ“Œ **Comentario del profesor:**

> â€œEsta puede ser la pregunta 1 del examen. Tiene que estar razonada, no solo nombrada.â€

---

**â“Pregunta 2 (test)**

> â€œÂ¿QuÃ© mÃ©trica usarÃ­as si la clase positiva es mucho menos frecuente que la negativa?â€

* Correcta: **F1-score** o **Recall**.
* Incorrecta: Accuracy (porque puede inducir a error si el modelo predice siempre la clase mayoritaria).

ğŸ“Œ **Refuerzo del profesor:**

> â€œNo usen accuracy a ciegas. Â¡Es una trampa!â€

---

**â“Pregunta 3 (ejercicio)**

> Dado un conjunto de mÃ©tricas de evaluaciÃ³n y resultados para tres modelos, Â¿cuÃ¡l seleccionarÃ­as?

* Se esperaba razonamiento: justificar elecciÃ³n segÃºn precisiÃ³n, recall, complejidad, tipo de problema, etc.
* Mencionar ventajas o riesgos (overfitting, interpretabilidad, tiempo de entrenamiento).

ğŸ“Œ **Enfoque del profesor:**

> â€œLes van a dar datos, y tendrÃ¡n que analizarlos como si fueran ustedes los que deciden quÃ© modelo implantar.â€

---

#### âœ… 2. EvaluaciÃ³n de relaciones entre variables

El profesor hizo especial Ã©nfasis en tÃ©cnicas estadÃ­sticas segÃºn el tipo de variables:

| Tipo de variables       | TÃ©cnica recomendada |
| ----------------------- | ------------------- |
| Continua â†” Continua     | CorrelaciÃ³n         |
| CategÃ³rica â†” Continua   | ANOVA               |
| CategÃ³rica â†” CategÃ³rica | Chi-cuadrado        |

ğŸ“Œ **Comentario importante:**

> â€œEsto cae casi seguro en el examen. Â¡Y lo hacen mal todo el tiempo!â€

---

#### âœ… 3. Pregunta tipo anÃ¡lisis con caso real

> *Se entrenÃ³ un modelo SVM con C=10 y se obtuvo una AUC de 0.71. Â¿QuÃ© podrÃ­as hacer para mejorarlo?*

* Ajustar hiperparÃ¡metros (modificar C, probar otro kernel).
* Escalar bien los datos (si no se hizo).
* Probar otras tÃ©cnicas de selecciÃ³n de caracterÃ­sticas.
* Considerar otro modelo si los resultados siguen bajos.

ğŸ“Œ **Lo esperado:**
Justificar, razonar y proponer mejoras concretas.

---

#### âœ… 4. AnÃ¡lisis de errores comunes

* Usar Label Encoding en variables nominales sin orden â†’ error.
* No escalar datos para SVM o KNN â†’ mala predicciÃ³n.
* Elegir modelo complejo cuando uno simple basta â†’ sobreajuste.
* Confundir precisiÃ³n con recall â†’ interpretaciÃ³n errÃ³nea.

ğŸ“Œ **Consejo del profesor:**

> â€œNo se trata de saberlo todo. Se trata de **entender quÃ© hacer con lo que saben**.â€

---

#### âœ… 5. ComparaciÃ³n entre mÃ©todos de ensemble

Repaso prÃ¡ctico:

* **Bagging**: modelos en paralelo, ideal para reducir varianza.
* **Boosting**: modelos en secuencia, enfocados en reducir sesgo.
* **Stacking**: combinaciÃ³n heterogÃ©nea con meta-modelo.

Se preguntÃ³ a los estudiantes:

> â€œÂ¿QuÃ© mÃ©todo usarÃ­as si tu modelo tiene alta varianza? Â¿Y si tiene alto sesgo?â€

ğŸ“Œ **Respuestas esperadas:**

* Alta varianza â†’ Bagging (Random Forest).
* Alto sesgo â†’ Boosting (AdaBoost, Gradient Boosting).

---

### ğŸ“Œ Ideas clave para repasar:

* Saber **cuÃ¡ndo aplicar una mÃ©trica y por quÃ©**.
* Justificar **la elecciÃ³n de modelos segÃºn el tipo de error o rendimiento esperado**.
* Practicar lectura e interpretaciÃ³n de salidas del modelo (matrices, grÃ¡ficos, mÃ©tricas).
* Entender relaciones entre variables y quÃ© pruebas estadÃ­sticas aplicar.

---

### ğŸ“ Consejos del profesor:

* â€œEn la parte de anÃ¡lisis, no hay respuestas Ãºnicas. Hay argumentos mejores.â€
* â€œPueden equivocarse en una fÃ³rmula, pero si explican el razonamiento, puntÃºa.â€
* â€œSi no recuerdan un nombre exacto, **describan la funciÃ³n o comportamiento del modelo.**â€

AquÃ­ tienes el **resumen completo y detallado de la clase del 23 de junio de 2025**, correspondiente al cierre del **Bloque 5: OptimizaciÃ³n de modelos supervisados**. Esta clase se enfocÃ³ en tÃ©cnicas avanzadas de bÃºsqueda de hiperparÃ¡metros, consideraciones estratÃ©gicas de ajuste fino y recomendaciones finales para abordar problemas reales con sentido prÃ¡ctico.

# ğŸ—“ï¸ Clase del 23 de junio de 2025

### ğŸ“š Tema: Bloque 5 (II) â€” TÃ©cnicas avanzadas de optimizaciÃ³n, ajuste fino y consejos finales

---

### ğŸ¯ **Objetivos de la clase:**

1. Profundizar en estrategias avanzadas de optimizaciÃ³n de modelos.
2. Aprender a ajustar configuraciones de hiperparÃ¡metros con criterio y sin sobrecoste.
3. Entender la lÃ³gica detrÃ¡s de Random Search y su ventaja en espacios grandes.
4. Anticipar preguntas aplicadas de examen sobre rendimiento y tuning.

---

### ğŸ§  **Contenidos tratados (teorÃ­a avanzada + aplicaciÃ³n prÃ¡ctica):**

---

#### âœ… 1. Recordatorio: Grid Search vs Random Search

* **Grid Search**:

  * Explora todo el espacio de forma exhaustiva.
  * Alto coste si hay muchos hiperparÃ¡metros o valores.
  * No siempre mejora los resultados si el espacio estÃ¡ mal definido.

* **Random Search**:

  * Selecciona combinaciones aleatorias.
  * MÃ¡s eficiente en espacios grandes y de alta dimensiÃ³n.
  * Alta probabilidad de encontrar buenas soluciones con menos pruebas.

ğŸ“Œ **Comentario del profesor:**

> â€œEn muchos estudios, Random Search supera a Grid Search en eficiencia prÃ¡ctica. No por probar mÃ¡s, se encuentra mejor.â€

---

#### âœ… 2. Estrategia de optimizaciÃ³n por etapas

* **Fase 1:** bÃºsqueda amplia (random) para ubicar regiones prometedoras.
* **Fase 2:** refinamiento en torno a los mejores resultados encontrados (rejilla localizada).
* **Fase 3 (opcional):** tuning de hiperparÃ¡metros secundarios o ajuste fino.

ğŸ“Œ **Ejemplo discutido:**

> Buscar inicialmente en C âˆˆ \[0.01, 1000] y gamma âˆˆ \[1eâ€“5, 1], luego refinar en torno a C = 10 y gamma = 0.1.

ğŸ“Œ **Consejo del profesor:**

> â€œNo hagan Grid Search sobre todo el espacio. Usen Random Search primero, luego profundicen.â€

---

#### âœ… 3. MÃ©tricas de evaluaciÃ³n para seleccionar la mejor configuraciÃ³n

* MÃ©tricas distintas llevan a diferentes â€œmejoresâ€ modelos.

  * Ej.: optimizar para F1-score â‰  optimizar para accuracy.
* El **criterio de evaluaciÃ³n debe coincidir con el objetivo del sistema**.

ğŸ“Œ **Comentario clave:**

> â€œSi el problema es detectar fraude, optimiza recall, no accuracy. Cada mÃ©trica cuenta una historia distinta.â€

---

#### âœ… 4. Criterios de parada

* Para evitar exceso de coste:

  * MÃ¡ximo de iteraciones.
  * Tiempo lÃ­mite.
  * NÃºmero de pasos sin mejora.

* Algunos frameworks permiten **Early Stopping**, especialmente Ãºtil en redes neuronales y boosting.

---

#### âœ… 5. ElecciÃ³n de modelo en base al contexto

El profesor repasÃ³ factores que deben influir en la elecciÃ³n final del modelo:

* Interpretabilidad.
* Velocidad de entrenamiento y predicciÃ³n.
* Robustez al ruido.
* Capacidad de generalizaciÃ³n.

ğŸ“Œ **Ejemplo prÃ¡ctico:**

> En un entorno mÃ©dico, mejor un modelo ligeramente menos preciso pero mÃ¡s interpretable (como regresiÃ³n logÃ­stica o Ã¡rbol).

---

#### âœ… 6. Consideraciones Ã©ticas y prÃ¡cticas

* Evitar sesgos en la selecciÃ³n de datos.
* No sobreoptimizar el modelo para un conjunto de validaciÃ³n concreto.
* Pensar en el coste computacional vs beneficio obtenido.

ğŸ“Œ **Comentario final del profesor:**

> â€œOptimizar no es hacer magia. Es encontrar un buen equilibrio entre rendimiento, coste y comprensiÃ³n del modelo.â€

---

### ğŸ“Œ Ideas clave para repasar:

* Saber explicar **por quÃ© Random Search es Ãºtil en problemas de muchos hiperparÃ¡metros**.
* Comprender cÃ³mo diseÃ±ar una **bÃºsqueda en dos fases**: amplia + refinada.
* Tener claro que el **criterio de evaluaciÃ³n define quÃ© es â€˜mejorâ€™**.
* Conocer **criterios de parada razonables** para no consumir recursos innecesarios.
* Relacionar el ajuste de modelos con el **contexto del problema y los objetivos del sistema**.

---

### ğŸ“ Consejos finales del profesor:

* â€œSi en el examen les piden proponer una estrategia de optimizaciÃ³n, no se limiten a decir â€˜Grid Searchâ€™. Expliquen su razonamiento.â€
* â€œElijan las mÃ©tricas en funciÃ³n del problema. No hay una â€˜mejorâ€™. Hay una mÃ¡s coherente con lo que se busca.â€
* â€œNo hace falta encontrar el modelo perfecto. Hace falta encontrar uno bueno y robusto, que sepan explicar y aplicar.â€
